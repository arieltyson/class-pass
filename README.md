# ğŸ“˜ **ClassPass â€“ Early Student Risk Detection (Custom ML Pipeline)**

**ClassPass** is a fully reproducible, interpretable machine-learning pipeline for early dropout-risk detection in higher education programs.  
It implements:

- A **custom from-scratch k-Nearest Neighbors classifier**  
- A **preprocessing and encoding pipeline**  
- **EDA + data auditing tools**  
- Train/validation/test splitting with hyperparameter tuning  
- **Explainability** via neighbor inspection  
- Model evaluation (F1, macro-F1, confusion matrix)

The system uses the UCI *Predict Studentsâ€™ Dropout and Academic Success* dataset and reduces the original 3-class label into a binary target:

- **At Risk** (Dropout)  
- **Continue** (Enrolled + Graduate)

Everything is implemented from first principles â€” no sklearn KNN, no automated pipelines â€” to demonstrate understanding of ML fundamentals and interpretability.

---

# ğŸš€ **Features**

### **ğŸ”§ Custom ML Model**
- Handmade **kNN classifier** supporting:
  - Euclidean / Manhattan distance  
  - Soft probability estimation  
  - Local neighbor explanations:
    > â€œ3 out of your 5 most similar students were At Risk.â€

### **ğŸ“Š EDA & Data Auditing**
- Missingness report  
- Class distribution  
- Top categorical values  
- Numerical summary statistics  
- Outputs JSON + CSV artifacts

### **ğŸ§¹ Preprocessing Pipeline**
- Automatic feature-type detection (numeric vs categorical)
- One-hot encoding  
- Standard or MinMax scaling  
- Stratified train/validation/test splitting  

### **ğŸ“ˆ Evaluation Tools**
- F1 (binary + macro)  
- Accuracy  
- Confusion matrix plot  
- Validation sweep over k  
- F1 vs k plot  
- Artifacts JSON saved for reproducibility  

### **ğŸ§ª Full Testing Suite**
- Tests for:
  - EDA structure  
  - kNN correctness  
  - Probability outputs  
  - Neighbor explanations  
  - Comparison vs sklearn KNN (sanity-check)

---

# ğŸ“ **Project Structure**

```
class-pass/
â”‚
â”œâ”€â”€ src/classpass/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ knn.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_eda.py
â”‚   â””â”€â”€ train_baseline.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ students.csv
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ eda/
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_eda.py
â”‚   â”œâ”€â”€ test_knn.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ CMPT-310-Proposal.pdf
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ pytest.ini
```

---

# ğŸ§° **Installation**

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

Place the UCI dataset in:

```
data/raw/students.csv
```

---

# ğŸ” **Run EDA**

```bash
python -m scripts.run_eda   --data data/raw/students.csv   --target Target   --binary   --outdir reports/eda
```

---

# ğŸ¤– **Train Baseline kNN**

```bash
python -m scripts.train_baseline   --data data/raw/students.csv   --target Target   --binary   --scaler standard   --distance euclidean   --k-grid 3,5,7,9,11   --outdir reports/figures
```

---

# ğŸ§ª **Run Tests**

```bash
pytest -q
```

---

# ğŸ“ˆ Example Performance

```
[Train] Best k: 3
Validation F1(At Risk): ~0.78

[Test metrics]
  accuracy:   0.896
  f1_binary:  0.819
  f1_macro:   0.873
```

---

# ğŸ“„ **License**

MIT License Â© 2025  
Ariel Tyson & Phil Akagu-Jones  
