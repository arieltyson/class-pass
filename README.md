# ğŸ“˜ **ClassPass â€“ Early Student Risk Detection (Custom ML Pipeline + Bayesian Network)**  

**ClassPass** is a fully reproducible, interpretable machine learning and probabilistic AI system for early dropout risk detection in higher education programs.  

It now implements the following AI paradigms:

- **Custom k-Nearest Neighbours classifier**  
- **Custom Decision Tree classifier**  
- **Bayesian Network for probabilistic inference**  

The system uses the UCI *Predict Studentsâ€™ Dropout and Academic Success* dataset and maps the original 3-class target into a binary label:

- **At Risk** (Dropout)  
- **Continue** (Enrolled + Graduate)

Everything is implemented from first principles to demonstrate clear ML fundamentals, interpretability, and reproducibility.

---

# ğŸš€ **Features**

## ğŸ”§ Custom ML Models

### **kNN (from scratch)**
- Euclidean / Manhattan distance  
- Predict 
- Neighbour explanations  

### **Decision Tree (from scratch)**
- Entropy or Gini impurity  
- Information gain  
- Customizable max depth  
- Rule extraction  
- Predict 

---

## ğŸ§  Bayesian Network 

A simple, interpretable Bayesian Network modelling dropout risk using:

```
LowGrades        \\
FinancialRisk ----> DropoutRisk
LowEngagement    //
```

Capabilities:
- Inference via enumeration  
- CPTs learned from the dataset  
- Produces dropout probabilities    
- Complements ML models for comparison  
---



# ğŸ§° **Installation**

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

Dataset goes in:

```
data/raw/students.csv
```

---

# ğŸ” **1. Run EDA**

```bash
python -m scripts.run_eda \
  --data data/raw/students.csv \
  --target Target \
  --binary \
  --outdir reports/eda
```

Outputs:
- `eda_summary.json`  
- `target_counts.csv`

---

# ğŸ¤– **2. Train kNN Baseline**

```bash
python -m scripts.train_baseline \
  --data data/raw/students.csv \
  --target Target \
  --binary \
  --scaler standard \
  --distance euclidean \
  --k-grid 3,5,7,9,11 \
  --outdir reports/figures
```

Outputs:
- `cm_knn.png`  
- `f1_vs_k.png`  
- `artifacts_knn.json`  

---

# ğŸŒ³ **3. Train Decision Tree**

```bash
python -m scripts.run_tree \
  --data data/raw/students.csv \
  --target Target \
  --binary \
  --criterion entropy \
  --depth-grid 3,5,7,9 \
  --outdir reports/figures_tree
```

Outputs:
- `cm_tree.png`  
- `tree_rules.txt`  
- `tree_artifacts.json`  

---

# ğŸ§  **4. Bayesian Network**

Run:

```bash
python -m scripts.run_bn \
  --data data/raw/students.csv \
  --target Target \
  --binary
```

Outputs:
- Bayesian Network metrics printed to console  

Example output:

```
[Bayesian Network Results]
  accuracy: X.XX
  f1_binary: X.XX
  f1_macro: X.XX
```

The BN is intentionally simple to highlight probabilistic reasoning and improve interpretability.

---

# ğŸ§ª **5. Run Tests**

```bash
pytest -q
```

Expected:

```
11 passed in X.XXs
```

---
# ğŸ“ **Project Structure**

```
class-pass/
â”‚
â”œâ”€â”€ src/classpass/
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ knn.py
â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”œâ”€â”€ bayesian_network.py      
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_eda.py
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ run_tree.py
â”‚   â””â”€â”€ run_bn.py                
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_eda.py
â”‚   â”œâ”€â”€ test_knn.py
â”‚   â”œâ”€â”€ test_decision_tree.py
â”‚   â””â”€â”€ test_bayesian_network.py
â”‚
â”œâ”€â”€ data/raw/students.csv
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ figures_tree/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ pytest.ini
```

---

# ğŸ“„ **License**

MIT License Â© 2025  
Ariel Tyson & Phil Akagu-Jones