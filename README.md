# ğŸ“˜ **ClassPass â€“ Early Student Risk Detection (Custom ML Pipeline)**  

**ClassPass** is a fully reproducible, interpretable machine-learning pipeline for early dropout-risk detection in higher education programs.  
It implements:

- A **custom from-scratch k-Nearest Neighbors classifier**  
- A **custom Decision Tree classifier** (entropy/Gini, interpretable rule extraction)  
- A full preprocessing and encoding pipeline  
- Separate scripts for EDA, kNN training, and Decision Tree training  
- Explainability tools (neighbors + rule extraction)  
- Validation-based model selection (tuning *k* or *max_depth*)  
- Train/val/test splits, metrics, confusion matrices, and artifacts

The system uses the UCI *Predict Studentsâ€™ Dropout and Academic Success* dataset and maps the original 3-class target into a binary label:

- **At Risk** (Dropout)  
- **Continue** (Enrolled + Graduate)

Everything is implemented from first principles to demonstrate clear ML fundamentals, interpretability, and reproducibility.

---

# ğŸš€ **Features**

### **ğŸ”§ Custom ML Models**
#### **kNN (from scratch)**
- Euclidean / Manhattan distance  
- Predict + predict_proba  
- Local neighbor explanations  

#### **Decision Tree (from scratch)**
- Entropy or Gini impurity  
- Information gain  
- Customizable max depth + min samples split  
- Human-readable rule extraction  
- Predict + predict_proba  

---

### **ğŸ“Š EDA & Data Auditing**
- Missingness report  
- Class balance  
- Basic numeric statistics  
- Top categorical values  
- JSON + CSV outputs

---

### **ğŸ§¹ Preprocessing**
- Automatic detection of numerical vs. categorical features  
- One-hot encoding  
- Standard or MinMax scaling  
- Stratified train/val/test splitting  

---

### **ğŸ“ˆ Evaluation Tools**
- F1 (binary + macro)  
- Accuracy  
- Confusion Matrix (with saved PNG)  
- F1 vs k plot  
- Artifacts JSON  

---

### **ğŸ§ª Testing**
- `test_eda.py` â€” validates EDA summary structure  
- `test_knn.py` â€” validates kNN correctness  
- `test_decision_tree.py` â€” validates tree predictions + rule generation  

---

# ğŸ“ **Project Structure**

```
class-pass/
â”‚
â”œâ”€â”€ src/classpass/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ knn.py
â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_eda.py
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â””â”€â”€ run_tree.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ students.csv
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ figures_tree/
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_eda.py
â”‚   â”œâ”€â”€ test_knn.py
â”‚   â”œâ”€â”€ test_decision_tree.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ CMPT-310-Proposal.pdf
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ pytest.ini
```

---

# ğŸ§° **Installation**

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

Place the dataset at:

```
data/raw/students.csv
```

The loader automatically handles semicolon-delimited UCI CSVs.

---

# ğŸ” **1. Run EDA**

```bash
python -m scripts.run_eda   --data data/raw/students.csv   --target Target   --binary   --outdir reports/eda
```

---

# ğŸ¤– **2. Train Baseline kNN**

```bash
python -m scripts.train_baseline   --data data/raw/students.csv   --target Target   --binary   --scaler standard   --distance euclidean   --k-grid 3,5,7,9,11   --outdir reports/figures
```

Outputs:

- `cm_knn.png`  
- `f1_vs_k.png`  
- `artifacts_knn.json`

---

# ğŸŒ³ **3. Train Decision Tree (NEW)**

```bash
python -m scripts.run_tree   --data data/raw/students.csv   --target Target   --binary   --criterion entropy   --depth-grid 3,5,7,9   --min-samples-split 2   --outdir reports/figures_tree
```

Outputs:

- `cm_tree.png`  
- `tree_rules.txt`  
- `tree_artifacts.json`  

---

# ğŸ§ª **4. Run Tests**

```bash
pytest -q
```

Expected:

```
7 passed in X.XXs
```

---

# ğŸ“ˆ Example kNN Performance

```
Validation F1(At Risk): ~0.78
Test accuracy:     ~0.896
Test F1_binary:    ~0.819
Test F1_macro:     ~0.873
```

---

# ğŸ“„ **License**

MIT License Â© 2025  
Ariel Tyson & Phil Akagu-Jones  
